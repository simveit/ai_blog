{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65baa395-692d-4080-b246-1a347f9b64fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inference with ü§ó "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797744e1-2741-406a-a657-6c94b5d2268b",
   "metadata": {},
   "source": [
    "In [this notebook](https://www.kaggle.com/code/simonveitner/a-first-model) I showed how to build a simple model in huggingface.\n",
    "\n",
    "Other from that I just used `trainer.save_model(\"trainer\")` to save my model in the folder `trainer`.\n",
    "\n",
    "From there i just need to exchange the loading of model file in the notebook and setup the trainer for inference mode as described in [here](https://discuss.huggingface.co/t/using-trainer-at-inference-time/9378/7). Everything else is pretty much the same üòä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76bf546-f458-4607-a864-d31b854fc9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset,DatasetDict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Set nice style\n",
    "plt.style.use(['dark_background'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71374cdc-d5bf-4ac9-b691-7adc80bfe2b7",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1162be6-8793-46ce-8c2b-7b4311f57a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"feedback-prize-english-language-learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb4e3b8-4969-4319-9de9-878b19e5740a",
   "metadata": {},
   "source": [
    "Get an overview of what is contained in our folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "382d7b06-f85f-43c2-96e9-f4076f16eb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test.csv  train.csv\n"
     ]
    }
   ],
   "source": [
    "!ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd37b044-7cf0-4dac-8d82-244a5bd566c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ss = pd.read_csv(path/\"sample_submission.csv\")\n",
    "df_tst = pd.read_csv(path/\"test.csv\")\n",
    "df_trn = pd.read_csv(path/\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d2985c7-b978-4d02-a4cf-092886cbce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_trn.columns[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7fbaa7-c8db-481c-a22a-2731ed2cb0c7",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c78c249-0404-49d6-8ff0-9691e1dfcc8c",
   "metadata": {},
   "source": [
    "To use the transformers we need a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f547b22-fab5-48fa-846f-ba538d6fa908",
   "metadata": {},
   "source": [
    "Let's initialize our tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71f577e0-3411-4e81-97bc-8ad2c1e6abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nm = 'trainer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e370985-1e14-4dda-b39b-3dd45bbcdb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokz = AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d86976-c9c4-44c9-a0b2-86dc787d7870",
   "metadata": {},
   "source": [
    "Let's see how exactly this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20488417-ab3b-45eb-8498-d89a3d8593ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‚ñÅI', '‚ñÅwant', '‚ñÅto', '‚ñÅget', '‚ñÅtoken', 'ized', '!']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokz.tokenize(\"I want to get tokenized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9378c3-10b7-43b8-9eee-22f8db511e03",
   "metadata": {},
   "source": [
    "We can encode..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56dc646b-ca00-42a6-8e66-2ffa6a8b03ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 273, 409, 264, 350, 10704, 4666, 300, 2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = tokz.encode((\"I want to get tokenized!\"))\n",
    "enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c5a7c0-aa0a-4152-bca6-c6141e30bbb0",
   "metadata": {},
   "source": [
    "... and decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a79ce76-d389-4dbf-990e-717ec47ec125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] I want to get tokenized![SEP]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokz.decode(enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bba764-9107-499a-82bb-5dad9381cc8d",
   "metadata": {},
   "source": [
    "Now we need to do 2 things:\n",
    "* tokenize our data, that means transforming the text into some form the computer can process\n",
    "* initialize our multi label for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e20f7d-86e2-4b4d-8c77-b0c4d07b2867",
   "metadata": {},
   "source": [
    "Let's first tackle the problem of generating categories:\n",
    "* We One hot encode\n",
    "* We use the resulting df to generate our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17808c5f-28c6-4ca4-93c7-d5b0af112ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdf = pd.get_dummies(df_trn, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0f1f223-d2ba-4525-9ffb-fe9e774b1ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_pandas(tempdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0559b3-a63d-4519-983a-f0d2fcc34e4f",
   "metadata": {},
   "source": [
    "Split in training and validation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99fa3b99-1237-41c5-84f6-38764c650f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_d = ds.train_test_split(0.25, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc79420-390b-4e5e-b617-2a6128505071",
   "metadata": {},
   "source": [
    "Mapping between labels and integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f1137e1-68e8-438e-bc28-da0703faa711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cohesion_1.0',\n",
       " 'cohesion_1.5',\n",
       " 'cohesion_2.0',\n",
       " 'cohesion_2.5',\n",
       " 'cohesion_3.0']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [label for label in ds_d['train'].features.keys() if label not in ['text_id', 'full_text']]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "843971c7-1cc4-45ee-98f5-d62b714d7a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(examples):\n",
    "    # take a batch of texts\n",
    "    text = examples[\"full_text\"]\n",
    "    # encode them\n",
    "    encoding = tokz(text, padding=\"max_length\", truncation=True, max_length=128)\n",
    "    # add labels\n",
    "    labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "    # create numpy array of shape (batch_size, num_labels)\n",
    "    labels_matrix = np.zeros((len(text), len(labels)))\n",
    "    # fill numpy array\n",
    "    for idx, label in enumerate(labels):\n",
    "        labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "    encoding[\"labels\"] = labels_matrix.tolist()\n",
    "  \n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10405feb-db2c-4786-9196-9ee2d78a6400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function preprocess_data at 0x7fe018278d30> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e17f1153624b2aa8337f5116578478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8289e1315e4b57b8ef6f9e76fcc1fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enc_ds_d = ds_d.map(preprocess_data, batched=True, remove_columns=ds_d['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07539bc2-b98b-4b86-970a-837bcd0f029c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2933\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 978\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_ds_d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a69459-9053-487e-8344-59e4d8e82d1d",
   "metadata": {},
   "source": [
    "Split in train and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1efe450-e4a4-481c-8027-3e161f092218",
   "metadata": {},
   "source": [
    "## Setting up the model & trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9f0b4f-264a-4d73-a664-91d59ea9da22",
   "metadata": {},
   "source": [
    "Setting up the metric..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "780a8cc7-8320-4fdd-bfc4-d84a64935aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcrmse(x,y): return np.mean(np.sqrt(np.mean((x-y)**2,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae96a31e-4e7a-4abf-8c43-2bbccc64a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([[1,1],[0,0]])\n",
    "x2 = np.array([[1,0],[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99c4628f-5e23-4013-b291-e30dc7bfe54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcrmse(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dbb7a85-9136-484b-97d6-1671ee0f4b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcrmse_d(eval_pred): return {'mcrmse': mcrmse(*eval_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52cf58b8-ee3f-413e-b7fb-83595af4575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments,Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6d98d4-e4b3-4d21-86a8-aef776df4ffb",
   "metadata": {},
   "source": [
    "...Batch size and metric name..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04eef77b-05ab-424d-a416-1243bea9a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "metric_name = \"mcrmse\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e241c8-9289-4b68-8236-d7e7970726d1",
   "metadata": {},
   "source": [
    "...the arguments..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc214e27-280a-4564-a5d7-a165b4209bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    f\"tst_out\",\n",
    "    do_train = False,\n",
    "    do_predict = True,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    dataloader_drop_last = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02dfff1b-9835-43a2-8006-c35f28c108c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "    \n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    mcrmse_acc = mcrmse(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'mcrmse': mcrmse_acc}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1bd3e8-c74e-46f6-b8c2-36c693dab13a",
   "metadata": {},
   "source": [
    "...the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd6e1a91-8f59-4ecb-9926-dae41b6634c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_nm, \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df7e1066-da17-4be7-bc7a-cc396b25dda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_ds_d.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889b4938-7f0e-4f59-9b4b-838297118db5",
   "metadata": {},
   "source": [
    "Let's verify a batch as well as a forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2095c76c-de85-42a1-a343-c13a01231d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_ds_d['train'][0]['labels'].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "194f7504-4ce6-40ce-bd48-c1c24a2a6e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    1,  4136,   269,   311,   265,   262,   370,   874,   470,   267,\n",
       "          291,   447,   260,  4136,   303,  1738,   265,  1451,   261,   306,\n",
       "          286,   610,  6135,  4986,   334,  2858,  8202,   261,  7934,   261,\n",
       "        13381,   795,  8202,   261,   263,   386,   310,   260,   450,   286,\n",
       "          610, 34772,   272,   783,   360,   803,   261,   528,   355,   261,\n",
       "          306,   402,   286,   347,  1085,   830,   334,   306,   286,   286,\n",
       "         1090,  8926, 16224,  1013,   262,  8425,   261,   311,   265,   349,\n",
       "          303,   266,  2553,  1013,   260,  1414,   273,   338,  3753,   288,\n",
       "         4136,   273,   338,   472,   264,   687,   308,   645,   401,   273,\n",
       "         1331,   308,   645,   284,   397,   324,  1964,   273, 40756,   834,\n",
       "        31452,   278,   322,   263,   262,   645,  1127,   324, 12516,   263,\n",
       "         7741,   260,   273,   338,   327,   472,   264,  2224,   277,   266,\n",
       "         2750,   263,  5771,   390,   262,   707,   260,     2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_ds_d['train']['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd2b8c38-4064-49cc-81fc-3729555139a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.1572, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), logits=tensor([[-7.6003, -6.2087, -1.6748, -0.1617, -0.7942, -2.9857, -5.6274, -7.9416,\n",
       "         -8.3018, -7.3899, -5.6492, -1.3790,  0.0663, -1.1804, -4.2006, -6.4937,\n",
       "         -8.1050, -8.4808, -8.3238, -6.9928, -3.2913, -0.7201,  0.4488, -3.5915,\n",
       "         -5.5989, -7.6971, -8.4161, -6.8264, -7.3330, -1.5203, -0.0205, -0.8572,\n",
       "         -3.8849, -5.9465, -8.1325, -8.1105, -7.3505, -6.5058, -0.8089, -0.1246,\n",
       "         -1.5866, -4.0718, -5.6008, -7.9227, -8.0366, -6.8729, -6.0449, -1.1963,\n",
       "          0.0729, -1.3299, -3.5036, -5.9796, -7.8256, -8.9868]],\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward pass\n",
    "outputs = model(input_ids=enc_ds_d['train']['input_ids'][0].unsqueeze(0), labels=enc_ds_d['train'][0]['labels'].unsqueeze(0))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e9fceec-6498-4a76-b83a-303c90b90fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=enc_ds_d[\"train\"],\n",
    "    eval_dataset=enc_ds_d[\"test\"],\n",
    "    tokenizer=tokz,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19801843-4e56-45b7-8a55-ea5a7d8b6a94",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd0fd8a-a49a-4752-9f82-e1ebcf1e5e09",
   "metadata": {},
   "source": [
    "Set up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5cebab2e-d455-486d-9844-0c9e448f3372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_func(x): return tokz(x[\"full_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6740ec8c-470b-4913-b162-41f29b5a3a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tst = Dataset.from_pandas(df_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38b23a27-5a5b-417f-85aa-3461af0673c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c1c1e835244395a5e4669f9a11a21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_ds = ds_tst.map(tok_func, batched=True, remove_columns=[\"text_id\",\"full_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53ffe7c9-bfa7-4f9b-8c25-41205a73b987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 3\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = trainer.predict(eval_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1d329b1-4adb-4fcb-a579-a55d743b7300",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_tt = torch.Tensor(preds.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6acc6ffa-52aa-4b6b-8339-59980c9c4808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply sigmoid + threshold\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(preds_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e700e5f-3279-434d-81ea-b90437264028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 54])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "737e7a63-8d19-4f28-a694-bc079470a2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.3149e-04, 1.6425e-03, 1.4542e-01, 4.5501e-01, 3.2861e-01,\n",
       "          5.1657e-02, 3.7629e-03, 3.3773e-04, 2.2183e-04],\n",
       "         [5.0841e-04, 2.9085e-03, 1.8654e-01, 5.1705e-01, 2.5370e-01,\n",
       "          1.5948e-02, 1.6301e-03, 2.7220e-04, 1.8518e-04],\n",
       "         [2.0637e-04, 7.6860e-04, 3.1243e-02, 3.1676e-01, 6.1975e-01,\n",
       "          2.9120e-02, 3.9431e-03, 4.3889e-04, 2.0195e-04],\n",
       "         [9.2469e-04, 5.5310e-04, 1.6003e-01, 4.7628e-01, 3.1655e-01,\n",
       "          2.2838e-02, 2.7699e-03, 2.7647e-04, 2.7412e-04],\n",
       "         [5.4792e-04, 1.2285e-03, 2.7858e-01, 4.6222e-01, 1.8477e-01,\n",
       "          1.9232e-02, 4.0661e-03, 3.4774e-04, 3.0245e-04],\n",
       "         [8.6861e-04, 1.9523e-03, 2.1894e-01, 5.2350e-01, 2.2068e-01,\n",
       "          3.2152e-02, 2.5723e-03, 3.9099e-04, 1.1256e-04]],\n",
       "\n",
       "        [[9.6675e-04, 3.8596e-03, 2.3323e-01, 4.9773e-01, 2.5149e-01,\n",
       "          3.2815e-02, 2.7687e-03, 3.8969e-04, 2.9928e-04],\n",
       "         [1.2245e-03, 6.5233e-03, 3.1888e-01, 5.1605e-01, 1.5547e-01,\n",
       "          1.0238e-02, 1.2655e-03, 3.7664e-04, 2.6395e-04],\n",
       "         [3.9965e-04, 1.5746e-03, 6.1339e-02, 3.8032e-01, 5.5359e-01,\n",
       "          1.7535e-02, 2.4546e-03, 5.0636e-04, 2.7842e-04],\n",
       "         [1.7846e-03, 1.1604e-03, 2.7300e-01, 5.2861e-01, 2.2545e-01,\n",
       "          1.3480e-02, 1.9217e-03, 3.3775e-04, 3.9268e-04],\n",
       "         [1.1056e-03, 2.7692e-03, 4.4649e-01, 4.6234e-01, 1.1940e-01,\n",
       "          9.3059e-03, 2.6974e-03, 4.4980e-04, 3.8357e-04],\n",
       "         [1.9633e-03, 4.2692e-03, 3.0920e-01, 5.1076e-01, 1.6183e-01,\n",
       "          2.1647e-02, 2.1585e-03, 4.6869e-04, 1.6160e-04]],\n",
       "\n",
       "        [[5.6670e-05, 1.4889e-04, 2.9396e-03, 4.3957e-02, 2.8636e-01,\n",
       "          5.2281e-01, 1.8473e-01, 4.0403e-03, 9.8352e-04],\n",
       "         [1.1397e-04, 1.3573e-04, 3.2018e-03, 2.5938e-02, 4.4911e-01,\n",
       "          4.8044e-01, 9.8053e-02, 2.3610e-03, 5.8633e-04],\n",
       "         [8.8751e-05, 1.3494e-04, 6.8702e-04, 1.0259e-02, 2.5660e-01,\n",
       "          5.0850e-01, 2.0871e-01, 5.2785e-03, 1.5634e-03],\n",
       "         [1.7101e-04, 5.5315e-05, 2.6744e-03, 2.1324e-02, 3.1220e-01,\n",
       "          5.1904e-01, 1.6054e-01, 5.1044e-03, 7.5152e-04],\n",
       "         [1.3115e-04, 1.1017e-04, 4.2908e-03, 4.7419e-02, 3.0202e-01,\n",
       "          4.8949e-01, 1.5539e-01, 5.1233e-03, 1.3146e-03],\n",
       "         [1.3011e-04, 2.1449e-04, 2.4913e-03, 2.9781e-02, 3.6902e-01,\n",
       "          4.5032e-01, 1.3317e-01, 5.5649e-03, 5.4810e-04]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_cat = torch.reshape(probs,(eval_ds.num_rows,6,-1))\n",
    "probs_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "635af928-dc53-4a26-884b-815876d385fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 4, 3, 3, 3],\n",
       "        [3, 3, 4, 3, 3, 3],\n",
       "        [5, 5, 5, 5, 5, 5]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.argmax(probs_cat, axis=2)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aed52fe-a97f-47c8-b399-4ebb96d02396",
   "metadata": {},
   "source": [
    "If we get prediction for the i'th column that means we have have for the category given by the row index\n",
    "\n",
    "$grad_{cat} = i * 0.5 + 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8629e8e-7645-4b36-b2c1-fa6035769fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.5000, 2.5000, 3.0000, 2.5000, 2.5000, 2.5000],\n",
       "        [2.5000, 2.5000, 3.0000, 2.5000, 2.5000, 2.5000],\n",
       "        [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades = pred*0.5+1\n",
    "grades "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed51ab65-fed7-47b7-9b95-684141c43bb8",
   "metadata": {},
   "source": [
    "Let's convert this to a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1aa3875a-1f95-4bf6-8163-84ec0ba27280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0000C359D63E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>000BAD50D026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>00367BB2546B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cohesion  syntax  vocabulary  phraseology  grammar  conventions  \\\n",
       "0       2.5     2.5         3.0          2.5      2.5          2.5   \n",
       "1       2.5     2.5         3.0          2.5      2.5          2.5   \n",
       "2       3.5     3.5         3.5          3.5      3.5          3.5   \n",
       "\n",
       "        text_id  \n",
       "0  0000C359D63E  \n",
       "1  000BAD50D026  \n",
       "2  00367BB2546B  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame(grades.numpy())\n",
    "sub.columns = df_ss.columns[1:]\n",
    "sub[\"text_id\"] = ds_tst[\"text_id\"]\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9629ee32-fe7a-4140-9045-bca5ede141f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  cohesion  syntax  vocabulary  phraseology  grammar  \\\n",
       "0  0000C359D63E       3.0     3.0         3.0          3.0      3.0   \n",
       "1  000BAD50D026       3.0     3.0         3.0          3.0      3.0   \n",
       "2  00367BB2546B       3.0     3.0         3.0          3.0      3.0   \n",
       "\n",
       "   conventions  \n",
       "0          3.0  \n",
       "1          3.0  \n",
       "2          3.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014db5b5-fbad-4286-a0e2-8ed67f499721",
   "metadata": {},
   "source": [
    "We need to rearrange the columns to get the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cde5affa-c2f1-4c6f-b56d-cd1616da7636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  cohesion  syntax  vocabulary  phraseology  grammar  \\\n",
       "0  0000C359D63E       2.5     2.5         3.0          2.5      2.5   \n",
       "1  000BAD50D026       2.5     2.5         3.0          2.5      2.5   \n",
       "2  00367BB2546B       3.5     3.5         3.5          3.5      3.5   \n",
       "\n",
       "   conventions  \n",
       "0          2.5  \n",
       "1          2.5  \n",
       "2          3.5  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = sub[df_ss.columns]\n",
    "sub "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
